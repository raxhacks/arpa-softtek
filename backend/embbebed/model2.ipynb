{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"/Users/luisbarajas/Documents/AGI/small_deeplearning.pdf\")\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=12000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "print(len(texts))\n",
    "# for(text) in texts:\n",
    "#     print(text.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import  Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI   \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "import pinecone\n",
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_API_ENV = os.getenv('PINECONE_API_ENV')\n",
    "\n",
    "pc = Pinecone(api_key=\"\")\n",
    "spec = ServerlessSpec(cloud=\"GCP\", region=\"us-central1\")\n",
    "index_name = 'reto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x129f1ae90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.01,\n",
       " 'namespaces': {'': {'vector_count': 1000}},\n",
       " 'total_vector_count': 1000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(client)\n",
    "\n",
    "pc = Pinecone(api_key=\"\")\n",
    "spec = ServerlessSpec(cloud=\"GCP\", region=\"us-central1\")\n",
    "index_name = 'reto'\n",
    "\n",
    "# check if index already exists (it shouldn't if this is your first run)\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name=index_name,\n",
    "        dimension=1536,  # dimensionality of text-embed-3-small\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "        # connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtexts\u001b[49m))): \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# i_end = min(i + batch_size, len(texts))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     i_end \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# texto = texts[i].page_content\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "count = 0\n",
    "for i in tqdm(range(0, len(texts))): \n",
    "    # i_end = min(i + batch_size, len(texts))\n",
    "    i_end = i + 1\n",
    "    # texto = texts[i].page_content\n",
    "    lines_batch = texts[i].page_content.split(\"\\n\")\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    res = client.embeddings.create(input=lines_batch, model=MODEL)\n",
    "    embeds = [record.embedding for record in res.data]\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # to_upsert = [{\"id\": id_, \"values\": embed, \"metadata\": meta} for id_, embed, meta in zip(ids_batch, embeds, meta)]\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"convolutional neural network\"\n",
    "xq = client.embeddings.create(input=query, model=MODEL).data[0].embedding\n",
    "result = index.query(vector=xq, top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74: 5.2 Convolutional networks\n",
      "0.68: convolutional layer, and its computational cost,\n",
      "0.50: Xconv-2dk=5maxpoolk=3reluconv-2dk=5maxpoolk=2relureshapefully-connrelufully-connË†P(Y)\n",
      "0.49: Xconv-2dk=1batchnormreluconv-2dk=3p=1batchnormreluconv-2dk=1batchnorm+reluY\n",
      "0.48: by a two-hidden-layer MLP to get the final C\n"
     ]
    }
   ],
   "source": [
    "for match in result['matches']: \n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'embed_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      2\u001b[0m     openai_api_key\u001b[38;5;241m=\u001b[39mOPENAI_API_KEY,\n\u001b[1;32m      3\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m text_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Pinecone(\n\u001b[0;32m---> 10\u001b[0m     index, \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m, text_field\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m     14\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     15\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'embed_query'"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "text_field = \"combined\"\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, client.embebd, text_field\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
